{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42b84ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"https://api.nasheedio.com/api/logs?fields[0]=id&fields[1]=createdAt&filters[type][$eq]=audio&populate[user][fields][0]=id&populate[audio][fields][0]=id&populate[audio][fields][1]=title\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775b7d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fetch_data import fetch_paginated_data\n",
    "from utils import get_latest_file, log_message\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012ed051",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "timestamp_str = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "week_number = now.isocalendar()[1]\n",
    "year = now.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a185b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FILE = \"./logs/processing.log\"\n",
    "MODEL_DIR = \"./models/\"\n",
    "DATA_DIR = \"./data/\"\n",
    "MAP_FOLDER = './map_data/'\n",
    "MATRIX_FOLDER = './matrix_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba32e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in [MODEL_DIR, DATA_DIR, MAP_FOLDER, MATRIX_FOLDER]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0103945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created log directory: ./logs\n"
     ]
    }
   ],
   "source": [
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(MAP_FOLDER, exist_ok=True)\n",
    "log_dir = os.path.dirname(LOG_FILE)\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    print(f\"Created log directory: {log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff2c9d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_save_weekly_data():\n",
    "    log_message(\"Fetching data from API...\")\n",
    "    logs_data = fetch_paginated_data(uri)\n",
    "    log_message(f\"Successfully fetched {len(logs_data)} records from the API.\")\n",
    "    json_logs_data = []\n",
    "    for item in logs_data:\n",
    "        log_id = item['id']\n",
    "        if item[\"attributes\"]['user']['data'] is None or item[\"attributes\"]['audio']['data'] is None:\n",
    "            continue\n",
    "        user_id = item[\"attributes\"]['user']['data']['id']\n",
    "        audio_id = item[\"attributes\"]['audio']['data']['id']\n",
    "        json_logs_data.append({\n",
    "            \"log_id\": log_id,\n",
    "            \"user_id\": user_id,\n",
    "            \"audio_id\": audio_id,\n",
    "            \"title\": item[\"attributes\"]['audio']['data']['attributes']['title'],\n",
    "            \"createdAt\": item[\"attributes\"]['createdAt']\n",
    "        })\n",
    "    df = pd.DataFrame(json_logs_data)\n",
    "\n",
    "    filename = f\"{DATA_DIR}/logs_{year}_week{week_number}_{timestamp_str}.parquet\"\n",
    "    df.to_parquet(filename, index=False)\n",
    "    log_message(f\"Saved data to Parquet file: {filename}\")\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1327d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_latest_weekly_data(filename = None):\n",
    "    if filename:\n",
    "        log_message(f\"Reading data from specified Parquet file: {filename}\")\n",
    "        return  pd.read_parquet(filename)\n",
    "    else:\n",
    "        most_recent_file = get_latest_file(DATA_DIR, 'logs', 'parquet')\n",
    "        if most_recent_file:\n",
    "            log_message(f\"Reading the latest Parquet file: {most_recent_file}\")\n",
    "            try:\n",
    "                return pd.read_parquet(most_recent_file)\n",
    "            except Exception as e:\n",
    "                log_message(f\"Error reading Parquet file {most_recent_file}: {e}\")\n",
    "                return None\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b2d792",
   "metadata": {},
   "source": [
    "MAKE SURE TO CHANGE IF YOU HAVE DATA ALREADY DOWNLOADED IN THE DIR\n",
    "- log_file = fetch_and_save_weekly_data()\n",
    "- latest_df = read_latest_weekly_data(log_file)\n",
    "- latest_df = read_latest_weekly_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2f78760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 14:45:04,790 - INFO - Total pages: 40 | Total records: 398073\n",
      "2025-05-16 14:45:18,106 - INFO - Page 2 processed successfully.\n",
      "2025-05-16 14:45:32,583 - INFO - Page 3 processed successfully.\n",
      "2025-05-16 14:45:47,491 - INFO - Page 4 processed successfully.\n",
      "2025-05-16 14:46:02,152 - INFO - Page 5 processed successfully.\n",
      "2025-05-16 14:46:16,883 - INFO - Page 6 processed successfully.\n",
      "2025-05-16 14:46:32,076 - INFO - Page 7 processed successfully.\n",
      "2025-05-16 14:46:46,659 - INFO - Page 8 processed successfully.\n",
      "2025-05-16 14:47:01,718 - INFO - Page 9 processed successfully.\n",
      "2025-05-16 14:47:17,005 - INFO - Page 10 processed successfully.\n",
      "2025-05-16 14:47:32,667 - INFO - Page 11 processed successfully.\n",
      "2025-05-16 14:47:47,789 - INFO - Page 12 processed successfully.\n",
      "2025-05-16 14:48:02,403 - INFO - Page 13 processed successfully.\n",
      "2025-05-16 14:48:17,167 - INFO - Page 14 processed successfully.\n",
      "2025-05-16 14:48:31,744 - INFO - Page 15 processed successfully.\n",
      "2025-05-16 14:48:47,163 - INFO - Page 16 processed successfully.\n",
      "2025-05-16 14:49:01,824 - INFO - Page 17 processed successfully.\n",
      "2025-05-16 14:49:16,713 - INFO - Page 18 processed successfully.\n",
      "2025-05-16 14:49:31,428 - INFO - Page 19 processed successfully.\n",
      "2025-05-16 14:49:46,224 - INFO - Page 20 processed successfully.\n",
      "2025-05-16 14:50:00,502 - INFO - Page 21 processed successfully.\n",
      "2025-05-16 14:50:16,149 - INFO - Page 22 processed successfully.\n",
      "2025-05-16 14:50:31,697 - INFO - Page 23 processed successfully.\n",
      "2025-05-16 14:50:46,190 - INFO - Page 24 processed successfully.\n",
      "2025-05-16 14:51:01,036 - INFO - Page 25 processed successfully.\n",
      "2025-05-16 14:51:15,782 - INFO - Page 26 processed successfully.\n",
      "2025-05-16 14:51:30,644 - INFO - Page 27 processed successfully.\n",
      "2025-05-16 14:51:45,624 - INFO - Page 28 processed successfully.\n",
      "2025-05-16 14:52:00,486 - INFO - Page 29 processed successfully.\n",
      "2025-05-16 14:52:15,649 - INFO - Page 30 processed successfully.\n",
      "2025-05-16 14:52:31,133 - INFO - Page 31 processed successfully.\n",
      "2025-05-16 14:52:46,508 - INFO - Page 32 processed successfully.\n",
      "2025-05-16 14:53:00,687 - INFO - Page 33 processed successfully.\n",
      "2025-05-16 14:53:15,148 - INFO - Page 34 processed successfully.\n",
      "2025-05-16 14:53:29,879 - INFO - Page 35 processed successfully.\n",
      "2025-05-16 14:53:45,224 - INFO - Page 36 processed successfully.\n",
      "2025-05-16 14:53:59,659 - INFO - Page 37 processed successfully.\n",
      "2025-05-16 14:54:14,515 - INFO - Page 38 processed successfully.\n",
      "2025-05-16 14:54:29,546 - INFO - Page 39 processed successfully.\n",
      "2025-05-16 14:54:41,388 - INFO - Page 40 processed successfully.\n",
      "2025-05-16 14:54:42,390 - INFO - Total records collected: 398074\n"
     ]
    }
   ],
   "source": [
    "log_file = fetch_and_save_weekly_data()\n",
    "latest_df = read_latest_weekly_data(log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92101205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "log_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "audio_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "createdAt",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e859b96b-00a2-49ca-9de2-9dae3888d981",
       "rows": [
        [
         "0",
         "1",
         "1475",
         "51450",
         "JAAN-E-GAZAB (Vocals only)",
         "2024-12-30T20:21:36.390Z"
        ],
        [
         "1",
         "2",
         "1475",
         "604",
         "Ya Aqsa",
         "2024-12-30T20:30:39.000Z"
        ],
        [
         "2",
         "17",
         "2333",
         "51450",
         "JAAN-E-GAZAB (Vocals only)",
         "2025-01-02T12:14:01.832Z"
        ],
        [
         "3",
         "18",
         "2381",
         "22692",
         "Salam us par ke jisne bekaso ki | Reel",
         "2025-01-02T12:16:36.017Z"
        ],
        [
         "4",
         "19",
         "2381",
         "22691",
         "Ek din Jibreel se kehne lage | The City School - Qaseeda Burda Shareef | Reel",
         "2025-01-02T12:17:06.251Z"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>audio_id</th>\n",
       "      <th>title</th>\n",
       "      <th>createdAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1475</td>\n",
       "      <td>51450</td>\n",
       "      <td>JAAN-E-GAZAB (Vocals only)</td>\n",
       "      <td>2024-12-30T20:21:36.390Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1475</td>\n",
       "      <td>604</td>\n",
       "      <td>Ya Aqsa</td>\n",
       "      <td>2024-12-30T20:30:39.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>2333</td>\n",
       "      <td>51450</td>\n",
       "      <td>JAAN-E-GAZAB (Vocals only)</td>\n",
       "      <td>2025-01-02T12:14:01.832Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2381</td>\n",
       "      <td>22692</td>\n",
       "      <td>Salam us par ke jisne bekaso ki | Reel</td>\n",
       "      <td>2025-01-02T12:16:36.017Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2381</td>\n",
       "      <td>22691</td>\n",
       "      <td>Ek din Jibreel se kehne lage | The City School...</td>\n",
       "      <td>2025-01-02T12:17:06.251Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_id  user_id  audio_id  \\\n",
       "0       1     1475     51450   \n",
       "1       2     1475       604   \n",
       "2      17     2333     51450   \n",
       "3      18     2381     22692   \n",
       "4      19     2381     22691   \n",
       "\n",
       "                                               title                 createdAt  \n",
       "0                         JAAN-E-GAZAB (Vocals only)  2024-12-30T20:21:36.390Z  \n",
       "1                                            Ya Aqsa  2024-12-30T20:30:39.000Z  \n",
       "2                         JAAN-E-GAZAB (Vocals only)  2025-01-02T12:14:01.832Z  \n",
       "3             Salam us par ke jisne bekaso ki | Reel  2025-01-02T12:16:36.017Z  \n",
       "4  Ek din Jibreel se kehne lage | The City School...  2025-01-02T12:17:06.251Z  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99181d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = latest_df.copy()\n",
    "df = df[['user_id', 'audio_id']]\n",
    "df.head()\n",
    "df['user_id'] = pd.to_numeric(df['user_id'])\n",
    "df['audio_id'] = pd.to_numeric(df['audio_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "641a50d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate play counts\n",
    "log_message(\"Processing interaction data...\")\n",
    "interactions = df.groupby(['user_id', 'audio_id']).size().reset_index(name='count')\n",
    "interactions['confidence'] = 1 + 40 * np.log1p(interactions['count'])\n",
    "\n",
    "# Filter out audios with only one listener\n",
    "item_user_counts = interactions.groupby('audio_id')['user_id'].nunique()\n",
    "valid_audio_ids = item_user_counts[item_user_counts > 0].index\n",
    "interactions = interactions[interactions['audio_id'].isin(valid_audio_ids)]\n",
    "\n",
    "# Map user/audio IDs to indices\n",
    "user_map = {id: i for i, id in enumerate(interactions['user_id'].unique())}\n",
    "item_map = {id: i for i, id in enumerate(interactions['audio_id'].unique())}\n",
    "inv_item_map = {v: k for k, v in item_map.items()}\n",
    "\n",
    "ITEM_MAP_FILE = f\"{MAP_FOLDER}/item_map_{year}_week{week_number}_{timestamp_str}.pkl\"\n",
    "INV_ITEM_MAP_FILE = f\"{MAP_FOLDER}/inv_item_map_{year}_week{week_number}_{timestamp_str}.pkl\"\n",
    "\n",
    "\n",
    "joblib.dump(item_map, ITEM_MAP_FILE)\n",
    "log_message(f\"Saved item_map to: {ITEM_MAP_FILE}\")\n",
    "joblib.dump(inv_item_map, INV_ITEM_MAP_FILE)\n",
    "log_message(f\"Saved inv_item_map to: {INV_ITEM_MAP_FILE}\")\n",
    "\n",
    "\n",
    "\n",
    "interactions['user_index'] = interactions['user_id'].map(user_map)\n",
    "interactions['item_index'] = interactions['audio_id'].map(item_map)\n",
    "\n",
    "# Create sparse item-user matrix\n",
    "log_message(\"Creating sparse matrix...\")\n",
    "matrix = coo_matrix(\n",
    "    (interactions['confidence'], (interactions['item_index'], interactions['user_index']))\n",
    ").tocsr()\n",
    "\n",
    "MATRIX_FILE = f\"{MATRIX_FOLDER}/matrix_{year}_week{week_number}_{timestamp_str}.pkl\"\n",
    "joblib.dump(matrix, MATRIX_FILE)\n",
    "log_message(f\"Saved matrix to: {MATRIX_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67ecf80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sabah\\Desktop\\Nasheedio\\venv\\Lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: OpenBLAS is configured to use 4 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fde0e9f5f64d0facc2179c5c4df3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_message(\"Training ALS model...\")\n",
    "als_model = AlternatingLeastSquares(factors=100, regularization=0.1, iterations=20, num_threads=0) # Added num_threads=0 for reproducibility\n",
    "als_model.fit(matrix)\n",
    "als_model_name = f\"{MODEL_DIR}/als_model_{year}_week{week_number}_{timestamp_str}.pkl\"\n",
    "joblib.dump(als_model, als_model_name)\n",
    "log_message(f\"Trained and saved ALS model: {als_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "644faae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_message(\"Training KNN fallback model...\")\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=10)\n",
    "knn_model.fit(matrix)\n",
    "knn_model_name = f\"{MODEL_DIR}/knn_model_{year}_week{week_number}_{timestamp_str}.pkl\"\n",
    "joblib.dump(knn_model, knn_model_name)\n",
    "log_message(f\"Trained and saved KNN model: {knn_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cb1a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_audios(audio_id: int, top_n: int = 5) -> dict:\n",
    "    \"\"\"Return top N similar audio IDs using ALS with KNN fallback.\"\"\"\n",
    "    als_model_path = get_latest_file('models', 'als', 'pkl')\n",
    "    knn_model_path = get_latest_file('models', 'knn', 'pkl')\n",
    "\n",
    "    if not als_model_path or not knn_model_path:\n",
    "        log_message(\"Could not load the latest ALS or KNN model.\")\n",
    "        return {'data': []}\n",
    "\n",
    "    try:\n",
    "        als_model = joblib.load(als_model_path)\n",
    "        knn_model = joblib.load(knn_model_path)\n",
    "        log_message(f\"Loaded ALS model from: {als_model_path}\")\n",
    "        log_message(f\"Loaded KNN model from: {knn_model_path}\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error loading models: {e}\")\n",
    "        return {'data': []}\n",
    "\n",
    "    if audio_id not in item_map:\n",
    "        log_message(f\"Audio ID {audio_id} not found in training data.\")\n",
    "        return {'data': []}\n",
    "\n",
    "    item_index = item_map[audio_id]\n",
    "\n",
    "    # Try ALS-based recommendations\n",
    "    try:\n",
    "        item_indices, _ = als_model.similar_items(item_index, N=top_n + 1)\n",
    "        recs = [inv_item_map[int(idx)] for idx in item_indices if int(idx) != item_index and int(idx) in inv_item_map]\n",
    "        if recs:\n",
    "            return {'data':\n",
    "                [int(x) for x in recs[:top_n]]\n",
    "            }\n",
    "    except Exception as e:\n",
    "        log_message(f\"ALS failed for Audio ID {audio_id}: {e}, falling back to KNN.\")\n",
    "\n",
    "    # Fallback to KNN if ALS fails or yields no useful results\n",
    "    try:\n",
    "        distances, indices = knn_model.kneighbors(matrix[item_index], n_neighbors=top_n + 1)\n",
    "        recs = [inv_item_map[int(i)] for i in indices.flatten() if int(i) != item_index and int(i) in inv_item_map]\n",
    "        return {'data':\n",
    "                [int(x) for x in recs[:top_n]]\n",
    "            }\n",
    "    except Exception as e:\n",
    "        log_message(f\"KNN also failed for Audio ID {audio_id}: {e}.\")\n",
    "        return {'data': []}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe668bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [18795, 18794, 18800, 1384, 722]}\n"
     ]
    }
   ],
   "source": [
    "recs = recommend_similar_audios(625)\n",
    "print(recs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
